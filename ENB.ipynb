{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0  # Replace with DeepFashion2 if available (preferred)\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tehre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\tehre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tehre\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "https://tfhub.dev/google/tf2-preview/deepfashion2/feature_vector/1 does not appear to be a valid module.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mReadError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_hub\\resolver.py:192\u001b[0m, in \u001b[0;36mDownloadManager.download_and_uncompress\u001b[1;34m(self, fileobj, dst_path)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m   \u001b[43mfile_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_tarfile_to_destination\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_progress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m   total_size_str \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39mbytes_to_readable_str(\n\u001b[0;32m    195\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_total_bytes_downloaded, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_hub\\file_utils.py:47\u001b[0m, in \u001b[0;36mextract_tarfile_to_destination\u001b[1;34m(fileobj, dst_path, log_function)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Extract a tarfile. Optional: log the progress.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtarfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr|*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfileobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfileobj\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m tgz:\n\u001b[0;32m     48\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m tarinfo \u001b[38;5;129;01min\u001b[39;00m tgz:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1008.0_x64__qbz5n2kfra8p0\\Lib\\tarfile.py:1836\u001b[0m, in \u001b[0;36mTarFile.open\u001b[1;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[0;32m   1835\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1836\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1837\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1008.0_x64__qbz5n2kfra8p0\\Lib\\tarfile.py:1712\u001b[0m, in \u001b[0;36mTarFile.__init__\u001b[1;34m(self, name, mode, fileobj, format, tarinfo, dereference, ignore_zeros, encoding, errors, pax_headers, debug, errorlevel, copybufsize)\u001b[0m\n\u001b[0;32m   1711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirstmember \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1712\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirstmember \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1715\u001b[0m     \u001b[38;5;66;03m# Move to the end of the archive,\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m     \u001b[38;5;66;03m# before the first empty block.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1008.0_x64__qbz5n2kfra8p0\\Lib\\tarfile.py:2622\u001b[0m, in \u001b[0;36mTarFile.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2621\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2622\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ReadError(\u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2623\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EmptyHeaderError:\n",
      "\u001b[1;31mReadError\u001b[0m: invalid header",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load\n\u001b[1;32m---> 13\u001b[0m   model \u001b[38;5;241m=\u001b[39m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://tfhub.dev/google/tf2-preview/deepfashion2/feature_vector/1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# DeepFashion2 feature extractor\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     15\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepFashion2 not found. Using EfficientNetB0 as fallback.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_hub\\module_v2.py:100\u001b[0m, in \u001b[0;36mload\u001b[1;34m(handle, tags, options)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     99\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a string, got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m handle)\n\u001b[1;32m--> 100\u001b[0m module_path \u001b[38;5;241m=\u001b[39m \u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m is_hub_module_v1 \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(_get_module_proto_path(module_path))\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m is_hub_module_v1:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_hub\\module_v2.py:55\u001b[0m, in \u001b[0;36mresolve\u001b[1;34m(handle)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresolve\u001b[39m(handle):\n\u001b[0;32m     32\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Resolves a module handle into a path.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03m  This function works both for plain TF2 SavedModels and the legacy TF1 Hub\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m    A string representing the Module path.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mregistry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresolver\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_hub\\registry.py:49\u001b[0m, in \u001b[0;36mMultiImplRegister.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m impl \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impls):\n\u001b[0;32m     48\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m impl\u001b[38;5;241m.\u001b[39mis_supported(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     fails\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mtype\u001b[39m(impl)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_hub\\compressed_module_resolver.py:81\u001b[0m, in \u001b[0;36mHttpCompressedFileResolver.__call__\u001b[1;34m(self, handle)\u001b[0m\n\u001b[0;32m     77\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_urlopen(request)\n\u001b[0;32m     78\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m resolver\u001b[38;5;241m.\u001b[39mDownloadManager(handle)\u001b[38;5;241m.\u001b[39mdownload_and_uncompress(\n\u001b[0;32m     79\u001b[0m       response, tmp_dir)\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matomic_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lock_file_timeout_sec\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_hub\\resolver.py:421\u001b[0m, in \u001b[0;36matomic_download\u001b[1;34m(handle, download_fn, module_dir, lock_file_timeout_sec)\u001b[0m\n\u001b[0;32m    419\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading TF-Hub Module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, handle)\n\u001b[0;32m    420\u001b[0m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mMakeDirs(tmp_dir)\n\u001b[1;32m--> 421\u001b[0m \u001b[43mdownload_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;66;03m# Write module descriptor to capture information about which module was\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \u001b[38;5;66;03m# downloaded by whom and when. The file stored at the same level as a\u001b[39;00m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;66;03m# directory in order to keep the content of the 'model_dir' exactly as it\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[38;5;66;03m# module caching protocol and no code in the TF-Hub library reads its\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# content.\u001b[39;00m\n\u001b[0;32m    431\u001b[0m _write_module_descriptor_file(handle, module_dir)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_hub\\compressed_module_resolver.py:78\u001b[0m, in \u001b[0;36mHttpCompressedFileResolver.__call__.<locals>.download\u001b[1;34m(handle, tmp_dir)\u001b[0m\n\u001b[0;32m     75\u001b[0m request \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_append_compressed_format_query(handle))\n\u001b[0;32m     77\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_urlopen(request)\n\u001b[1;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresolver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDownloadManager\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_uncompress\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tensorflow_hub\\resolver.py:200\u001b[0m, in \u001b[0;36mDownloadManager.download_and_uncompress\u001b[1;34m(self, fileobj, dst_path)\u001b[0m\n\u001b[0;32m    196\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_print_download_progress_msg(\n\u001b[0;32m    197\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloaded \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, Total size: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url, total_size_str),\n\u001b[0;32m    198\u001b[0m       flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m tarfile\u001b[38;5;241m.\u001b[39mReadError:\n\u001b[1;32m--> 200\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m does not appear to be a valid module.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url)\n",
      "\u001b[1;31mOSError\u001b[0m: https://tfhub.dev/google/tf2-preview/deepfashion2/feature_vector/1 does not appear to be a valid module."
     ]
    }
   ],
   "source": [
    "def extract_features(img_path, model):\n",
    "  \"\"\"Extracts features from an image using a pre-trained model.\"\"\"\n",
    "  img = image.load_img(img_path, target_size=(224, 224))  # Adjust size as needed\n",
    "  img_data = image.img_to_array(img)\n",
    "  img_data = np.expand_dims(img_data, axis=0)\n",
    "  # Preprocessing might be needed depending on the chosen model (check DeepFashion2 documentation)\n",
    "  features = model.predict(img_data)\n",
    "  return features.flatten()\n",
    "\n",
    "# Load pre-trained model (replace with DeepFashion2 if available)\n",
    "try:\n",
    "\n",
    "  from tensorflow_hub import load\n",
    "  model = load('https://tfhub.dev/google/tf2-preview/deepfashion2/feature_vector/1')\n",
    "except ImportError:\n",
    "  print(\"DeepFashion2 not found. Using EfficientNetB0 as fallback.\")\n",
    "  base_model = EfficientNetB0(weights='imagenet', include_top=False)  # Use pre-trained layers for feature extraction\n",
    "  model = Model(inputs=base_model.input, outputs=base_model.get_layer('avg_pool').output)  # Extract features before final classification layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_histogram_similarity(image1, image2):\n",
    "  # Extract color histograms (replace with your implementation)\n",
    "  hist1 = extract_color_histogram(image1)\n",
    "  hist2 = extract_color_histogram(image2)\n",
    "  # Use Earth Mover's Distance or Chi-Square Distance for comparing histograms (replace with your implementation)\n",
    "  similarity = emd(hist1, hist2)  # Replace with appropriate function\n",
    "  return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbp_similarity(image1, image2):\n",
    "  # Extract Local Binary Patterns (replace with your implementation)\n",
    "  lbp1 = extract_lbp(image1)\n",
    "  lbp2 = extract_lbp(image2)\n",
    "  # Use Jaccard Similarity to compare LBP sets\n",
    "  similarity = jaccard_similarity(lbp1, lbp2)\n",
    "  return similarity\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "  intersection = len(set1.intersection(set2))\n",
    "  union = len(set1.union(set2))\n",
    "  return intersection / float(union)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # ... (your existing code for scraping or using brand API)\n",
    "image_dir = r\"D:\\Study\\Sem5\\ML\\Web scrapping\\Clothing Store Scrapper\\Eid_edit\"\n",
    "    \n",
    "# List all image files in the directory\n",
    "image_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
    "\n",
    "# Extract features from downloaded images\n",
    "image_features = []\n",
    "for img_file in image_files:\n",
    "    features = extract_features(img_file, model)\n",
    "    image_features.append(features)\n",
    "\n",
    "image_features = np.array(image_features)\n",
    "  # Extract features from scraped/downloaded images\n",
    "\n",
    "  # User image path\n",
    "user_img_path = 'path/to/user/image.jpg'\n",
    "\n",
    "# Choose appropriate similarity measure based on feature extraction method\n",
    "# similarity = cosine_similarity([user_features], image_features)  # For pre-trained models\n",
    "similarity = color_histogram_similarity(user_img_path, image1_path)  # Replace with your chosen similarity function\n",
    "\n",
    "# ... (your existing code for finding top similar images and displaying recommendations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load pre-trained ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('avg_pool').output)\n",
    "\n",
    "# Your existing code for web scraping and downloading images remains the same\n",
    "\n",
    "# Feature Extraction using ResNet50\n",
    "def extract_features(img_path, model):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_data = image.img_to_array(img)\n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    img_data = preprocess_input(img_data)\n",
    "    features = model.predict(img_data)\n",
    "    return features.flatten()\n",
    "\n",
    "# Your existing code for calculating similarity and making recommendations remains the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import feature\n",
    "\n",
    "def extract_color_histogram(image, bins=(8, 8, 8)):\n",
    "    # Load the image, convert it to the HSV color space, and compute a color histogram\n",
    "    image = cv2.imread(image)\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins, [0, 180, 0, 256, 0, 256])\n",
    "    # Normalize the histogram\n",
    "    cv2.normalize(hist, hist)\n",
    "    # Return the flattened histogram as the feature vector\n",
    "    return hist.flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lbp(image, num_points=24, radius=8):\n",
    "    # Load the image in grayscale, compute LBP features, and return the histogram\n",
    "    image = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n",
    "    lbp = feature.local_binary_pattern(image, num_points, radius, method=\"uniform\")\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, num_points + 3), range=(0, num_points + 2))\n",
    "    # Normalize the histogram\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-7)\n",
    "    return hist\n",
    "\n",
    "# Your existing code for color_histogram_similarity, lbp_similarity, and jaccard_similarity remains the same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lbp_similarity(image1, image2):\n",
    "  # Extract Local Binary Patterns (replace with your implementation)\n",
    "  lbp1 = extract_lbp(image1)\n",
    "  lbp2 = extract_lbp(image2)\n",
    "  # Use Jaccard Similarity to compare LBP sets\n",
    "  similarity = jaccard_similarity(lbp1, lbp2)\n",
    "  return similarity\n",
    "\n",
    "def jaccard_similarity(set1, set2):\n",
    "  intersection = len(set1.intersection(set2))\n",
    "  union = len(set1.union(set2))\n",
    "  return intersection / float(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_histogram_similarity(image1, image2):\n",
    "  # Extract color histograms (replace with your implementation)\n",
    "  hist1 = extract_color_histogram(image1)\n",
    "  hist2 = extract_color_histogram(image2)\n",
    "  # Use Earth Mover's Distance or Chi-Square Distance for comparing histograms (replace with your implementation)\n",
    "  similarity = emd(hist1, hist2)  # Replace with appropriate function\n",
    "  return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't convert object to 'str' for 'filename'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 27\u001b[0m\n\u001b[0;32m     23\u001b[0m user_features \u001b[38;5;241m=\u001b[39m extract_color_histogram(user_img_path)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# user_features = extract_lbp(user_img_path)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Choose appropriate similarity measure based on feature extraction method\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# similarity1 = cosine_similarity([user_features], image_features)  # For pre-trained models\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m similarity2 \u001b[38;5;241m=\u001b[39m \u001b[43mcolor_histogram_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_features\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Replace with your chosen similarity function\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# ... (your existing code for finding top similar images and displaying recommendations)\u001b[39;00m\n\u001b[0;32m     30\u001b[0m top_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(similarity2[\u001b[38;5;241m0\u001b[39m])[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m:][::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Top 5 similar images\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m, in \u001b[0;36mcolor_histogram_similarity\u001b[1;34m(image1, image2)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcolor_histogram_similarity\u001b[39m(image1, image2):\n\u001b[0;32m      2\u001b[0m   \u001b[38;5;66;03m# Extract color histograms (replace with your implementation)\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m   hist1 \u001b[38;5;241m=\u001b[39m \u001b[43mextract_color_histogram\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m   hist2 \u001b[38;5;241m=\u001b[39m extract_color_histogram(image2)\n\u001b[0;32m      5\u001b[0m   \u001b[38;5;66;03m# Use Earth Mover's Distance or Chi-Square Distance for comparing histograms (replace with your implementation)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[16], line 7\u001b[0m, in \u001b[0;36mextract_color_histogram\u001b[1;34m(image, bins)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_color_histogram\u001b[39m(image, bins\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m)):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Load the image, convert it to the HSV color space, and compute a color histogram\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     hsv \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2HSV)\n\u001b[0;32m      9\u001b[0m     hist \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcalcHist([hsv], [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m], \u001b[38;5;28;01mNone\u001b[39;00m, bins, [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m180\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m256\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: Can't convert object to 'str' for 'filename'"
     ]
    }
   ],
   "source": [
    "\n",
    "  # Extract features from scraped/downloaded images\n",
    "image_dir = r\"D:\\Study\\Sem5\\ML\\Web scrapping\\Clothing Store Scrapper\\Eid_edit\"\n",
    "    \n",
    "# List all image files in the directory\n",
    "image_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
    "\n",
    "    # Extract features from downloaded images\n",
    "\n",
    "\n",
    "  # User image path\n",
    "\n",
    "image_features = []\n",
    "for img_file in image_files:\n",
    "    # Choose appropriate feature extraction method based on your requirements\n",
    "    # features = extract_color_histogram(img_file)  # For color histogram similarity\n",
    "    features = extract_lbp(img_file)  # For LBP similarity\n",
    "    image_features.append(features)\n",
    "\n",
    "image_features = np.array(image_features)\n",
    "\n",
    "  # User image path\n",
    "user_img_path = r\"D:\\Study\\Sem5\\ML\\Web scrapping\\Clothing Store Scrapper\\user_images\\image_16.jpg\"  # Change this to the user's image path\n",
    "# user_features = extract_color_histogram(user_img_path)\n",
    "user_features = extract_lbp(user_img_path)\n",
    "  # Choose appropriate similarity measure based on feature extraction method\n",
    "# similarity1 = cosine_similarity([user_features], image_features)  # For pre-trained models\n",
    "similarity2 = color_histogram_similarity(image_features, user_features)  # Replace with your chosen similarity function\n",
    "\n",
    "  # ... (your existing code for finding top similar images and displaying recommendations)\n",
    "top_indices = np.argsort(similarity2[0])[-5:][::-1]  # Top 5 similar images\n",
    "recommended_images = [image_files[i] for i in top_indices]\n",
    "\n",
    "for img_file in recommended_images:\n",
    "    print(img_file)\n",
    "print(\"----------------\")\n",
    "# top_indices = np.argsort(similarity2[0])[-5:][::-1]  # Top 5 similar images\n",
    "# recommended_images = [image_files[i] for i in top_indices]\n",
    "\n",
    "# for img_file in recommended_images:\n",
    "#     print(img_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
